import re
import sys
import yaml
import os
import argparse
import time
from urllib.parse import urlparse, urljoin
import requests
from requests.exceptions import Timeout, ConnectionError
from bs4 import BeautifulSoup
import socket
import concurrent.futures
from pathlib import Path

def check_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–åº“"""
    missing_deps = []
    
    try:
        import yaml
    except ImportError:
        missing_deps.append("pyyaml")
    
    try:
        import requests
    except ImportError:
        missing_deps.append("requests")
    
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        missing_deps.append("beautifulsoup4")
    
    if missing_deps:
        print(f"é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ï¼š{', '.join(missing_deps)}")
        print("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
        print(f"pip install {' '.join(missing_deps)}")
        sys.exit(1)

def get_domain(url):
    """æå–URLä¸­çš„åŸŸåéƒ¨åˆ†"""
    try:
        return urlparse(url).netloc
    except:
        return None

def download_favicon(url, output_path):
    """ä¸‹è½½å›¾æ ‡åˆ°æœ¬åœ°æ–‡ä»¶"""
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(response.content)
            return True
        else:
            print(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False
    except Exception as e:
        print(f"ä¸‹è½½å›¾æ ‡æ—¶å‡ºé”™: {e}")
        return False

def extract_icon(url, output_dir="assets/logos"):
    """
    æ™ºèƒ½æå–ç½‘ç«™å›¾æ ‡ï¼ŒæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§å°è¯•ï¼š
    1. æ ‡å‡†favicon.ico
    2. HTMLä¸­å®šä¹‰çš„å›¾æ ‡æ ‡ç­¾
    3. ç¬¬ä¸‰æ–¹å›¾æ ‡æœåŠ¡
    """
    domain = get_domain(url)
    if not domain:
        return "link"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, f"{domain}.png")
    
    # 1. å°è¯•æ ‡å‡†favicon.ico
    print(f"å°è¯•è·å– {domain} çš„æ ‡å‡†favicon.ico...")
    icon_url = f"https://{domain}/favicon.ico"
    try:
        response = requests.head(icon_url, timeout=3)
        if response.status_code == 200:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            content_length = response.headers.get('Content-Length')
            if content_length and int(content_length) > 1024:  # å¤§äº1KB
                print(f"æ‰¾åˆ°æ ‡å‡†favicon.icoï¼Œå¼€å§‹ä¸‹è½½...")
                if download_favicon(icon_url, output_file):
                    print(f"å›¾æ ‡å·²ä¿å­˜åˆ°: {output_file}")
                    return f"assets/logos/{domain}.png"
    except Exception as e:
        print(f"è·å–æ ‡å‡†favicon.icoå¤±è´¥: {e}")
    
    # 2. å°è¯•ä»HTMLä¸­æå–å›¾æ ‡
    print(f"å°è¯•ä» {url} çš„HTMLä¸­æå–å›¾æ ‡...")
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å›¾æ ‡æ ‡ç­¾
            icon_candidates = []
            
            # æŸ¥æ‰¾<link>æ ‡ç­¾ä¸­çš„å›¾æ ‡
            for link in soup.find_all('link'):
                rel = link.get('rel', [])
                if isinstance(rel, str):
                    rel = [rel]
                rel = [r.lower() for r in rel]
                
                if 'icon' in rel or 'shortcut icon' in rel:
                    href = link.get('href')
                    if href:
                        # å¤„ç†ç›¸å¯¹è·¯å¾„
                        if href.startswith('//'):
                            href = f"https:{href}"
                        elif not href.startswith('http'):
                            href = urljoin(url, href)
                        
                        # å°è¯•è·å–å›¾æ ‡å¤§å°
                        size = link.get('sizes')
                        width = 0
                        if size and 'x' in size:
                            try:
                                width = int(size.split('x')[0])
                            except:
                                pass
                        
                        icon_candidates.append((href, width))
            
            # æŒ‰å°ºå¯¸æ’åºï¼Œä¼˜å…ˆé€‰æ‹©è¾ƒå¤§çš„å›¾æ ‡
            if icon_candidates:
                icon_candidates.sort(key=lambda x: x[1], reverse=True)
                best_icon = icon_candidates[0][0]
                
                print(f"ä»HTMLä¸­æ‰¾åˆ°å›¾æ ‡: {best_icon}ï¼Œå¼€å§‹ä¸‹è½½...")
                if download_favicon(best_icon, output_file):
                    print(f"å›¾æ ‡å·²ä¿å­˜åˆ°: {output_file}")
                    return f"assets/logos/{domain}.png"
    
    except (Timeout, ConnectionError, socket.gaierror, Exception) as e:
        print(f"ä»HTMLä¸­è·å–å›¾æ ‡å¤±è´¥: {e}")
    
    # 3. ä½¿ç”¨ç¬¬ä¸‰æ–¹å›¾æ ‡æœåŠ¡
    print(f"ä½¿ç”¨ç¬¬ä¸‰æ–¹æœåŠ¡è·å– {domain} çš„å›¾æ ‡...")
    third_party_api = f"https://api.iowen.cn/favicon/{domain}.png"
    try:
        print(f"ä» {third_party_api} ä¸‹è½½å›¾æ ‡...")
        if download_favicon(third_party_api, output_file):
            print(f"å›¾æ ‡å·²ä¿å­˜åˆ°: {output_file}")
            return f"assets/logos/{domain}.png"
    except Exception as e:
        print(f"ä½¿ç”¨ç¬¬ä¸‰æ–¹æœåŠ¡è·å–å›¾æ ‡å¤±è´¥: {e}")
    
    # 4. åŸŸåæ˜ å°„çš„é»˜è®¤å›¾æ ‡
    domain_parts = domain.split('.')
    if len(domain_parts) > 1:
        name_part = domain_parts[-2].lower()
        if name_part == 'github':
            return 'github'
        elif name_part == 'gitlab':
            return 'gitlab'
        elif name_part == 'bitbucket':
            return 'bitbucket'
        elif name_part == 'react':
            return 'react'
        elif name_part == 'vuejs':
            return 'vuejs'
        elif name_part == 'angular':
            return 'angular'
        elif name_part == 'figma':
            return 'figma'
        elif name_part == 'youtube':
            return 'youtube'
        elif name_part == 'stackoverflow':
            return 'stack-overflow'
        elif name_part == 'twitter':
            return 'twitter'
        elif name_part == 'facebook':
            return 'facebook'
        elif name_part == 'linkedin':
            return 'linkedin'
    
    # 5. é»˜è®¤å›é€€å›¾æ ‡
    print(f"æœªèƒ½è·å– {domain} çš„å›¾æ ‡ï¼Œä½¿ç”¨é»˜è®¤å›¾æ ‡")
    return "link"

def parse_chrome_bookmarks(html_content):
    """è§£æChrome/Edgeå¯¼å‡ºçš„HTMLä¹¦ç­¾æ–‡ä»¶"""
    # åˆå§‹åŒ–ç±»åˆ«æ ˆï¼ˆç”¨äºè·Ÿè¸ªå½“å‰æ–‡ä»¶å¤¹å±‚çº§ï¼‰
    category_stack = []
    categories = {}
    
    # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    folder_start_pattern = re.compile(r'<DT><H3[^>]*>(.*?)</H3>')
    folder_end_pattern = re.compile(r'</DL><p>')
    bookmark_pattern = re.compile(r'<DT><A HREF="(.*?)"[^>]*>(.*?)</A>')
    
    lines = html_content.split('\n')
    current_folder = None
    ignore_top_level = False
    
    print("æ­£åœ¨è§£æHTMLå†…å®¹...")
    start_time = time.time()
    
    for i, line in enumerate(lines):
        # æ¯å¤„ç†1000è¡Œæ˜¾ç¤ºè¿›åº¦
        if i % 1000 == 0 and i > 0:
            print(f"å·²å¤„ç† {i}/{len(lines)} è¡Œ")
        
        # æ£€æŸ¥æ˜¯å¦å¼€å§‹ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹
        folder_match = folder_start_pattern.search(line)
        if folder_match:
            folder_name = folder_match.group(1)
            
            # æ£€æµ‹æ˜¯å¦ä¸ºEdgeçš„"æ”¶è—å¤¹æ "é¡¶çº§æ–‡ä»¶å¤¹
            if not category_stack and folder_name.lower() in ['æ”¶è—å¤¹æ ', 'favorites bar']:
                ignore_top_level = True
                continue
                
            folder_id = folder_name.lower().replace(' ', '-')
            
            # åˆ›å»ºæ–°ç±»åˆ«
            category = {
                'id': folder_id,
                'name': folder_name,
                'icon': 'folder',  # é»˜è®¤æ–‡ä»¶å¤¹å›¾æ ‡
                'sections': []
            }
            
            # å¤„ç†åµŒå¥—å±‚çº§
            if ignore_top_level:
                # Edgeå¯¼å‡ºæ ¼å¼ - å¿½ç•¥é¡¶çº§æ–‡ä»¶å¤¹
                if len(category_stack) == 0:
                    # ä¸€çº§ç±»åˆ«
                    categories[folder_id] = category
                    current_folder = category
                elif len(category_stack) == 1:
                    # äºŒçº§ç±»åˆ«ï¼ˆè½¬æ¢ä¸ºsectionsï¼‰
                    section = {
                        'name': folder_name,
                        'websites': []
                    }
                    category_stack[0]['sections'].append(section)
                    current_folder = section
                else:
                    # ä¸‰çº§ç±»åˆ« - åˆå¹¶åˆ°çˆ¶çº§sections
                    if 'websites' not in category_stack[-1]:
                        category_stack[-1]['websites'] = []
                    current_folder = category_stack[-1]
            else:
                # Chromeå¯¼å‡ºæ ¼å¼ - æ­£å¸¸å±‚çº§å¤„ç†
                if len(category_stack) == 0:
                    # ä¸€çº§ç±»åˆ«
                    categories[folder_id] = category
                    current_folder = category
                elif len(category_stack) == 1:
                    # äºŒçº§ç±»åˆ«ï¼ˆsectionsï¼‰
                    section = {
                        'name': folder_name,
                        'websites': []
                    }
                    category_stack[0]['sections'].append(section)
                    current_folder = section
                else:
                    # ä¸‰çº§ç±»åˆ« - åˆå¹¶åˆ°çˆ¶çº§sections
                    if 'websites' not in category_stack[-1]:
                        category_stack[-1]['websites'] = []
                    current_folder = category_stack[-1]
            
            # å°†æ­¤æ–‡ä»¶å¤¹å‹å…¥æ ˆ
            category_stack.append(current_folder)
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸä¸€ä¸ªæ–‡ä»¶å¤¹
        if folder_end_pattern.search(line):
            if category_stack:
                category_stack.pop()
                if category_stack:
                    current_folder = category_stack[-1]
                else:
                    current_folder = None
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºä¹¦ç­¾
        bookmark_match = bookmark_pattern.search(line)
        if bookmark_match and current_folder:
            url = bookmark_match.group(1)
            name = bookmark_match.group(2)
            
            # æ·»åŠ åˆ°å½“å‰æ–‡ä»¶å¤¹çš„ç½‘ç«™åˆ—è¡¨
            website_entry = {
                'name': name,
                'url': url,
                'icon': 'loading',  # åˆå§‹çŠ¶æ€
                'description': name  # ä¸å†åŒ…å«åŸŸå
            }
            
            if 'websites' in current_folder:
                current_folder['websites'].append(website_entry)
            elif 'sections' in current_folder and current_folder['sections']:
                current_folder['sections'][0]['websites'].append(website_entry)
            else:
                if 'sections' not in current_folder:
                    current_folder['sections'] = []
                section = {
                    'name': 'é»˜è®¤åˆ†ç±»',
                    'websites': []
                }
                current_folder['sections'].append(section)
                section['websites'].append(website_entry)
    
    end_time = time.time()
    print(f"HTMLè§£æå®Œæˆï¼Œè€—æ—¶ {end_time - start_time:.2f} ç§’")
    
    return list(categories.values())

def fetch_icons_concurrently(yaml_data, output_dir="assets/logos", max_workers=10):
    """ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–ç½‘ç«™å›¾æ ‡"""
    websites = []
    
    # æ”¶é›†æ‰€æœ‰ç½‘ç«™æ¡ç›®
    for category in yaml_data:
        if 'sections' in category:
            for section in category['sections']:
                if 'websites' in section:
                    for website in section['websites']:
                        websites.append(website)
        elif 'websites' in category:
            for website in category['websites']:
                websites.append(website)
    
    total = len(websites)
    print(f"å‡†å¤‡è·å– {total} ä¸ªç½‘ç«™çš„å›¾æ ‡...")
    
    if not websites:
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–å›¾æ ‡
    start_time = time.time()
    processed = 0
    successes = 0
    failures = 0
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_website = {executor.submit(extract_icon, website['url'], output_dir): website for website in websites}
        
        for future in concurrent.futures.as_completed(future_to_website):
            website = future_to_website[future]
            try:
                icon = future.result()
                website['icon'] = icon
                processed += 1
                
                if icon.startswith("assets/logos/") or icon != "link":
                    successes += 1
                    status = "âœ…"
                else:
                    failures += 1
                    status = "âŒ"
                
                # æ˜¾ç¤ºè¿›åº¦æ¡
                progress = processed / total
                bar_length = 50
                filled_length = int(bar_length * progress)
                bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
                elapsed = time.time() - start_time
                eta = (elapsed / processed * (total - processed)) if processed > 0 else 0
                
                print(f"\r{status} è¿›åº¦: [{bar}] {progress:.1%} | å·²å¤„ç†: {processed}/{total} | æˆåŠŸ: {successes} | å¤±è´¥: {failures} | ç”¨æ—¶: {elapsed:.1f}s | é¢„è®¡å‰©ä½™: {eta:.1f}s", end='')
                
            except Exception as e:
                processed += 1
                failures += 1
                website['icon'] = "link"  # é»˜è®¤å›¾æ ‡
                
                # æ˜¾ç¤ºè¿›åº¦æ¡
                progress = processed / total
                bar_length = 50
                filled_length = int(bar_length * progress)
                bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
                elapsed = time.time() - start_time
                eta = (elapsed / processed * (total - processed)) if processed > 0 else 0
                
                print(f"\râŒ è¿›åº¦: [{bar}] {progress:.1%} | å·²å¤„ç†: {processed}/{total} | æˆåŠŸ: {successes} | å¤±è´¥: {failures} | ç”¨æ—¶: {elapsed:.1f}s | é¢„è®¡å‰©ä½™: {eta:.1f}s", end='')
    
    print(f"\nå›¾æ ‡è·å–å®Œæˆï¼Œæ€»è€—æ—¶ {time.time() - start_time:.2f} ç§’")
    print(f"æˆåŠŸè·å–: {successes}/{total} ({successes/total*100:.1f}%)")
    print(f"ä½¿ç”¨é»˜è®¤å›¾æ ‡: {failures}/{total} ({failures/total*100:.1f}%)")
    print(f"å›¾æ ‡ä¿å­˜ç›®å½•: {os.path.abspath(output_dir)}")

def convert_bookmark_to_yaml(input_file, output_file):
    print(f"å¼€å§‹å¤„ç†: {input_file}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨")
        sys.exit(1)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
    if not os.access(input_file, os.R_OK):
        print(f"é”™è¯¯ï¼šæ²¡æœ‰è¯»å–æ–‡ä»¶ '{input_file}' çš„æƒé™")
        sys.exit(1)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_file)
    if output_dir and not os.path.exists(output_dir):
        try:
            os.makedirs(output_dir)
            print(f"åˆ›å»ºç›®å½•: {output_dir}")
        except Exception as e:
            print(f"é”™è¯¯ï¼šæ— æ³•åˆ›å»ºç›®å½• '{output_dir}': {e}")
            sys.exit(1)
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å¯å†™
    if output_dir and not os.access(output_dir, os.W_OK):
        print(f"é”™è¯¯ï¼šæ²¡æœ‰å†™å…¥ç›®å½• '{output_dir}' çš„æƒé™")
        sys.exit(1)
    
    # è¯»å–HTMLæ–‡ä»¶
    print(f"è¯»å–HTMLæ–‡ä»¶: {input_file}")
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        print(f"æ–‡ä»¶å¤§å°: {len(html_content) / 1024:.2f} KB")
    except Exception as e:
        print(f"é”™è¯¯ï¼šè¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        sys.exit(1)
    
    # è§£æä¹¦ç­¾
    yaml_data = parse_chrome_bookmarks(html_content)
    
    if not yaml_data:
        print("è­¦å‘Šï¼šè§£æç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯ä¹¦ç­¾æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
        sys.exit(1)
    
    # è®¡ç®—æ€»ç½‘ç«™æ•°
    total_websites = sum(len(s.get('websites', [])) for c in yaml_data for s in c.get('sections', []))
    print(f"è§£æå®Œæˆï¼Œå‘ç° {len(yaml_data)} ä¸ªåˆ†ç±»ï¼Œå…± {total_websites} ä¸ªç½‘ç«™")
    
    # è·å–å›¾æ ‡
    if total_websites > 0:
        # ç¡®ä¿assets/logosç›®å½•å­˜åœ¨äºè¾“å‡ºæ–‡ä»¶åŒçº§ç›®å½•
        output_parent = os.path.dirname(output_file)
        logos_dir = os.path.join(output_parent, "assets/logos")
        fetch_icons_concurrently(yaml_data, logos_dir)
    else:
        print("æ²¡æœ‰æ‰¾åˆ°ç½‘ç«™ï¼Œè·³è¿‡å›¾æ ‡è·å–")
    
    # å†™å…¥YAMLæ–‡ä»¶
    print(f"å†™å…¥YAMLæ–‡ä»¶åˆ° {output_file}...")
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
        print(f"YAMLæ–‡ä»¶å·²ä¿å­˜ï¼Œå¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")
    except Exception as e:
        print(f"é”™è¯¯ï¼šå†™å…¥YAMLæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        sys.exit(1)
    
    print(f"\nè½¬æ¢å®Œæˆï¼ğŸ‰\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"å¤„ç†ç»Ÿè®¡:")
    print(f"  åˆ†ç±»æ•°: {len(yaml_data)}")
    print(f"  ç½‘ç«™æ€»æ•°: {total_websites}")
    print(f"  æˆåŠŸè·å–å›¾æ ‡: {sum(1 for c in yaml_data for s in c.get('sections', []) for w in s.get('websites', []) if w['icon'].startswith('assets/logos/'))}")
    print(f"  ä½¿ç”¨é»˜è®¤å›¾æ ‡: {sum(1 for c in yaml_data for s in c.get('sections', []) for w in s.get('websites', []) if not w['icon'].startswith('assets/logos/'))}")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    check_dependencies()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å°†Chrome/Edgeä¹¦ç­¾è½¬æ¢ä¸ºYAMLæ ¼å¼')
    parser.add_argument('input_file', help='Chrome/Edgeä¹¦ç­¾HTMLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('output_file', nargs='?', default='websites.yaml', help='è¾“å‡ºYAMLæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºwebsites.yamlï¼‰')
    parser.add_argument('--workers', '-w', type=int, default=10, help='å¹¶å‘è·å–å›¾æ ‡çš„çº¿ç¨‹æ•°')
    
    try:
        args = parser.parse_args()
    except argparse.ArgumentError as e:
        print(f"å‚æ•°é”™è¯¯: {e}")
        parser.print_help()
        sys.exit(1)
    
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶æœ‰æ‰©å±•å
    if args.output_file and not os.path.splitext(args.output_file)[1]:
        args.output_file += '.yaml'
    
    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    print("=" * 50)
    print("Chrome/Edgeä¹¦ç­¾è½¬æ¢å·¥å…·")
    print("=" * 50)
    
    # å¼€å§‹è½¬æ¢
    convert_bookmark_to_yaml(args.input_file, args.output_file)    