import re
import sys
import yaml
import os
import argparse
from urllib.parse import urlparse, urljoin
import requests
from requests.exceptions import Timeout, ConnectionError
from bs4 import BeautifulSoup
import socket
import concurrent.futures
import time

def check_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–åº“"""
    missing_deps = []
    
    try:
        import yaml
    except ImportError:
        missing_deps.append("pyyaml")
    
    try:
        import requests
    except ImportError:
        missing_deps.append("requests")
    
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        missing_deps.append("beautifulsoup4")
    
    if missing_deps:
        print(f"é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ï¼š{', '.join(missing_deps)}")
        print("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
        print(f"pip install {' '.join(missing_deps)}")
        sys.exit(1)

def get_domain(url):
    try:
        return urlparse(url).netloc
    except:
        return None

def extract_icon(url):
    """
    æ™ºèƒ½æå–ç½‘ç«™å›¾æ ‡ï¼ŒæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§å°è¯•ï¼š
    1. HTMLä¸­å®šä¹‰çš„è¾ƒå¤§å°ºå¯¸å›¾æ ‡
    2. æ ‡å‡†favicon.ico
    3. Googleå›¾æ ‡æœåŠ¡
    4. åŸŸåæ˜ å°„çš„é»˜è®¤å›¾æ ‡
    """
    domain = get_domain(url)
    if not domain:
        return "link"
    
    # 1. å°è¯•ä»HTMLä¸­æå–é«˜è´¨é‡å›¾æ ‡
    try:
        response = requests.get(url, timeout=3)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å›¾æ ‡æ ‡ç­¾
            icon_candidates = []
            
            # æŸ¥æ‰¾<link>æ ‡ç­¾ä¸­çš„å›¾æ ‡
            for link in soup.find_all('link'):
                rel = link.get('rel', [])
                if isinstance(rel, str):
                    rel = [rel]
                rel = [r.lower() for r in rel]
                
                if 'icon' in rel or 'shortcut icon' in rel:
                    href = link.get('href')
                    if href:
                        # å¤„ç†ç›¸å¯¹è·¯å¾„
                        if href.startswith('//'):
                            href = f"https:{href}"
                        elif not href.startswith('http'):
                            href = urljoin(url, href)
                        
                        # å°è¯•è·å–å›¾æ ‡å¤§å°
                        size = link.get('sizes')
                        width = 0
                        if size and 'x' in size:
                            try:
                                width = int(size.split('x')[0])
                            except:
                                pass
                        
                        icon_candidates.append((href, width))
            
            # æŒ‰å°ºå¯¸æ’åºï¼Œä¼˜å…ˆé€‰æ‹©è¾ƒå¤§çš„å›¾æ ‡
            if icon_candidates:
                icon_candidates.sort(key=lambda x: x[1], reverse=True)
                best_icon = icon_candidates[0][0]
                
                # éªŒè¯å›¾æ ‡æœ‰æ•ˆæ€§
                try:
                    icon_resp = requests.head(best_icon, timeout=2)
                    if icon_resp.status_code == 200:
                        return best_icon
                except:
                    pass
    
    except (Timeout, ConnectionError, socket.gaierror, Exception) as e:
        print(f"è­¦å‘Šï¼šè·å– {url} çš„HTMLå›¾æ ‡æ—¶å‡ºé”™: {e}")
        pass
    
    # 2. å°è¯•æ ‡å‡†favicon.ico
    icon_url = f"https://{domain}/favicon.ico"
    try:
        response = requests.head(icon_url, timeout=2)
        if response.status_code == 200:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œè¿‡å°çš„å¯èƒ½æ˜¯ä½è´¨é‡å›¾æ ‡
            content_length = response.headers.get('Content-Length')
            if content_length and int(content_length) > 1024:  # å¤§äº1KB
                return icon_url
    except Exception as e:
        print(f"è­¦å‘Šï¼šè·å– {url} çš„favicon.icoæ—¶å‡ºé”™: {e}")
        pass
    
    # 3. ä½¿ç”¨Googleå›¾æ ‡æœåŠ¡ä½œä¸ºåå¤‡
    try:
        google_icon = f"https://www.google.com/s2/favicons?sz=64&domain={domain}"
        response = requests.head(google_icon, timeout=2)
        if response.status_code == 200:
            return google_icon
    except Exception as e:
        print(f"è­¦å‘Šï¼šä½¿ç”¨GoogleæœåŠ¡è·å– {url} çš„å›¾æ ‡æ—¶å‡ºé”™: {e}")
        pass
    
    # 4. åŸŸåæ˜ å°„çš„é»˜è®¤å›¾æ ‡
    domain_parts = domain.split('.')
    if len(domain_parts) > 1:
        name_part = domain_parts[-2].lower()
        if name_part == 'github':
            return 'github'
        elif name_part == 'gitlab':
            return 'gitlab'
        elif name_part == 'bitbucket':
            return 'bitbucket'
        elif name_part == 'react':
            return 'react'
        elif name_part == 'vuejs':
            return 'vuejs'
        elif name_part == 'angular':
            return 'angular'
        elif name_part == 'figma':
            return 'figma'
        elif name_part == 'youtube':
            return 'youtube'
        elif name_part == 'stackoverflow':
            return 'stack-overflow'
        elif name_part == 'twitter':
            return 'twitter'
        elif name_part == 'facebook':
            return 'facebook'
        elif name_part == 'linkedin':
            return 'linkedin'
    
    # 5. é»˜è®¤å›é€€å›¾æ ‡
    return "link"

def parse_chrome_bookmarks(html_content):
    """è§£æChrome/Edgeå¯¼å‡ºçš„HTMLä¹¦ç­¾æ–‡ä»¶"""
    # åˆå§‹åŒ–ç±»åˆ«æ ˆï¼ˆç”¨äºè·Ÿè¸ªå½“å‰æ–‡ä»¶å¤¹å±‚çº§ï¼‰
    category_stack = []
    categories = {}
    
    # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    folder_start_pattern = re.compile(r'<DT><H3[^>]*>(.*?)</H3>')
    folder_end_pattern = re.compile(r'</DL><p>')
    bookmark_pattern = re.compile(r'<DT><A HREF="(.*?)"[^>]*>(.*?)</A>')
    
    lines = html_content.split('\n')
    current_folder = None
    ignore_top_level = False
    
    print("æ­£åœ¨è§£æHTMLå†…å®¹...")
    start_time = time.time()
    
    for i, line in enumerate(lines):
        # æ¯å¤„ç†1000è¡Œæ˜¾ç¤ºè¿›åº¦
        if i % 1000 == 0 and i > 0:
            print(f"å·²å¤„ç† {i}/{len(lines)} è¡Œ")
        
        # æ£€æŸ¥æ˜¯å¦å¼€å§‹ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹
        folder_match = folder_start_pattern.search(line)
        if folder_match:
            folder_name = folder_match.group(1)
            
            # æ£€æµ‹æ˜¯å¦ä¸ºEdgeçš„"æ”¶è—å¤¹æ "é¡¶çº§æ–‡ä»¶å¤¹
            if not category_stack and folder_name.lower() in ['æ”¶è—å¤¹æ ', 'favorites bar']:
                ignore_top_level = True
                continue
                
            folder_id = folder_name.lower().replace(' ', '-')
            
            # åˆ›å»ºæ–°ç±»åˆ«
            category = {
                'id': folder_id,
                'name': folder_name,
                'icon': 'folder',  # é»˜è®¤æ–‡ä»¶å¤¹å›¾æ ‡
                'sections': []
            }
            
            # å¤„ç†åµŒå¥—å±‚çº§
            if ignore_top_level:
                # Edgeå¯¼å‡ºæ ¼å¼ - å¿½ç•¥é¡¶çº§æ–‡ä»¶å¤¹
                if len(category_stack) == 0:
                    # ä¸€çº§ç±»åˆ«
                    categories[folder_id] = category
                    current_folder = category
                elif len(category_stack) == 1:
                    # äºŒçº§ç±»åˆ«ï¼ˆè½¬æ¢ä¸ºsectionsï¼‰
                    section = {
                        'name': folder_name,
                        'websites': []
                    }
                    category_stack[0]['sections'].append(section)
                    current_folder = section
                else:
                    # ä¸‰çº§ç±»åˆ« - åˆå¹¶åˆ°çˆ¶çº§sections
                    if 'websites' not in category_stack[-1]:
                        category_stack[-1]['websites'] = []
                    current_folder = category_stack[-1]
            else:
                # Chromeå¯¼å‡ºæ ¼å¼ - æ­£å¸¸å±‚çº§å¤„ç†
                if len(category_stack) == 0:
                    # ä¸€çº§ç±»åˆ«
                    categories[folder_id] = category
                    current_folder = category
                elif len(category_stack) == 1:
                    # äºŒçº§ç±»åˆ«ï¼ˆsectionsï¼‰
                    section = {
                        'name': folder_name,
                        'websites': []
                    }
                    category_stack[0]['sections'].append(section)
                    current_folder = section
                else:
                    # ä¸‰çº§ç±»åˆ« - åˆå¹¶åˆ°çˆ¶çº§sections
                    if 'websites' not in category_stack[-1]:
                        category_stack[-1]['websites'] = []
                    current_folder = category_stack[-1]
            
            # å°†æ­¤æ–‡ä»¶å¤¹å‹å…¥æ ˆ
            category_stack.append(current_folder)
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸä¸€ä¸ªæ–‡ä»¶å¤¹
        if folder_end_pattern.search(line):
            if category_stack:
                category_stack.pop()
                if category_stack:
                    current_folder = category_stack[-1]
                else:
                    current_folder = None
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºä¹¦ç­¾
        bookmark_match = bookmark_pattern.search(line)
        if bookmark_match and current_folder:
            url = bookmark_match.group(1)
            name = bookmark_match.group(2)
            
            # æ·»åŠ åˆ°å½“å‰æ–‡ä»¶å¤¹çš„ç½‘ç«™åˆ—è¡¨
            website_entry = {
                'name': name,
                'url': url,
                'icon': 'loading',  # åˆå§‹çŠ¶æ€
                'description': name  # ä¸å†åŒ…å«åŸŸå
            }
            
            if 'websites' in current_folder:
                current_folder['websites'].append(website_entry)
            elif 'sections' in current_folder and current_folder['sections']:
                current_folder['sections'][0]['websites'].append(website_entry)
            else:
                if 'sections' not in current_folder:
                    current_folder['sections'] = []
                section = {
                    'name': 'é»˜è®¤åˆ†ç±»',
                    'websites': []
                }
                current_folder['sections'].append(section)
                section['websites'].append(website_entry)
    
    end_time = time.time()
    print(f"HTMLè§£æå®Œæˆï¼Œè€—æ—¶ {end_time - start_time:.2f} ç§’")
    
    return list(categories.values())

def fetch_icons_concurrently(yaml_data, max_workers=10):
    """ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–ç½‘ç«™å›¾æ ‡"""
    websites = []
    
    # æ”¶é›†æ‰€æœ‰ç½‘ç«™æ¡ç›®
    for category in yaml_data:
        if 'sections' in category:
            for section in category['sections']:
                if 'websites' in section:
                    for website in section['websites']:
                        websites.append(website)
        elif 'websites' in category:
            for website in category['websites']:
                websites.append(website)
    
    total = len(websites)
    print(f"å‡†å¤‡è·å– {total} ä¸ªç½‘ç«™çš„å›¾æ ‡...")
    
    if not websites:
        return
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–å›¾æ ‡
    start_time = time.time()
    processed = 0
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_website = {executor.submit(extract_icon, website['url']): website for website in websites}
        
        for future in concurrent.futures.as_completed(future_to_website):
            website = future_to_website[future]
            try:
                icon = future.result()
                website['icon'] = icon
                processed += 1
                
                # æ˜¾ç¤ºè¿›åº¦æ¡
                progress = processed / total
                bar_length = 50
                filled_length = int(bar_length * progress)
                bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
                elapsed = time.time() - start_time
                eta = (elapsed / processed * (total - processed)) if processed > 0 else 0
                
                print(f"\rè¿›åº¦: [{bar}] {progress:.1%} | å·²å¤„ç†: {processed}/{total} | ç”¨æ—¶: {elapsed:.1f}s | é¢„è®¡å‰©ä½™: {eta:.1f}s", end='')
                
            except Exception as e:
                print(f"\né”™è¯¯ï¼šè·å– {website['url']} çš„å›¾æ ‡æ—¶å‡ºé”™: {e}")
                website['icon'] = "link"  # é»˜è®¤å›¾æ ‡
    
    print(f"\nå›¾æ ‡è·å–å®Œæˆï¼Œæ€»è€—æ—¶ {time.time() - start_time:.2f} ç§’")

def convert_bookmark_to_yaml(input_file, output_file):
    print(f"å¼€å§‹å¤„ç†: {input_file}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨")
        sys.exit(1)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
    if not os.access(input_file, os.R_OK):
        print(f"é”™è¯¯ï¼šæ²¡æœ‰è¯»å–æ–‡ä»¶ '{input_file}' çš„æƒé™")
        sys.exit(1)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_file)
    if output_dir and not os.path.exists(output_dir):
        try:
            os.makedirs(output_dir)
            print(f"åˆ›å»ºç›®å½•: {output_dir}")
        except Exception as e:
            print(f"é”™è¯¯ï¼šæ— æ³•åˆ›å»ºç›®å½• '{output_dir}': {e}")
            sys.exit(1)
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å¯å†™
    if output_dir and not os.access(output_dir, os.W_OK):
        print(f"é”™è¯¯ï¼šæ²¡æœ‰å†™å…¥ç›®å½• '{output_dir}' çš„æƒé™")
        sys.exit(1)
    
    # è¯»å–HTMLæ–‡ä»¶
    print(f"è¯»å–HTMLæ–‡ä»¶: {input_file}")
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        print(f"æ–‡ä»¶å¤§å°: {len(html_content) / 1024:.2f} KB")
    except Exception as e:
        print(f"é”™è¯¯ï¼šè¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        sys.exit(1)
    
    # è§£æä¹¦ç­¾
    yaml_data = parse_chrome_bookmarks(html_content)
    
    if not yaml_data:
        print("è­¦å‘Šï¼šè§£æç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯ä¹¦ç­¾æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
        sys.exit(1)
    
    # è®¡ç®—æ€»ç½‘ç«™æ•°
    total_websites = sum(len(s.get('websites', [])) for c in yaml_data for s in c.get('sections', []))
    print(f"è§£æå®Œæˆï¼Œå‘ç° {len(yaml_data)} ä¸ªåˆ†ç±»ï¼Œå…± {total_websites} ä¸ªç½‘ç«™")
    
    # è·å–å›¾æ ‡
    if total_websites > 0:
        fetch_icons_concurrently(yaml_data)
    else:
        print("æ²¡æœ‰æ‰¾åˆ°ç½‘ç«™ï¼Œè·³è¿‡å›¾æ ‡è·å–")
    
    # å†™å…¥YAMLæ–‡ä»¶
    print(f"å†™å…¥YAMLæ–‡ä»¶åˆ° {output_file}...")
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
        print(f"YAMLæ–‡ä»¶å·²ä¿å­˜ï¼Œå¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")
    except Exception as e:
        print(f"é”™è¯¯ï¼šå†™å…¥YAMLæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        sys.exit(1)
    
    print(f"\nè½¬æ¢å®Œæˆï¼ğŸ‰\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"å¤„ç†ç»Ÿè®¡:")
    print(f"  åˆ†ç±»æ•°: {len(yaml_data)}")
    print(f"  ç½‘ç«™æ€»æ•°: {total_websites}")
    print(f"  æˆåŠŸè·å–å›¾æ ‡: {sum(1 for c in yaml_data for s in c.get('sections', []) for w in s.get('websites', []) if w['icon'] != 'link')}")
    print(f"  ä½¿ç”¨é»˜è®¤å›¾æ ‡: {sum(1 for c in yaml_data for s in c.get('sections', []) for w in s.get('websites', []) if w['icon'] == 'link')}")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    check_dependencies()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å°†Chrome/Edgeä¹¦ç­¾è½¬æ¢ä¸ºYAMLæ ¼å¼')
    parser.add_argument('input_file', help='Chrome/Edgeä¹¦ç­¾HTMLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('output_file', nargs='?', default='websites.yaml', help='è¾“å‡ºYAMLæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºwebsites.yamlï¼‰')
    parser.add_argument('--workers', '-w', type=int, default=10, help='å¹¶å‘è·å–å›¾æ ‡çš„çº¿ç¨‹æ•°')
    
    try:
        args = parser.parse_args()
    except argparse.ArgumentError as e:
        print(f"å‚æ•°é”™è¯¯: {e}")
        parser.print_help()
        sys.exit(1)
    
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶æœ‰æ‰©å±•å
    if args.output_file and not os.path.splitext(args.output_file)[1]:
        args.output_file += '.yaml'
    
    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    print("=" * 50)
    print("Chrome/Edgeä¹¦ç­¾è½¬æ¢å·¥å…·")
    print("=" * 50)
    
    # å¼€å§‹è½¬æ¢
    convert_bookmark_to_yaml(args.input_file, args.output_file)    